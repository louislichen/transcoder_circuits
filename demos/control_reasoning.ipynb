{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3114200d",
   "metadata": {},
   "source": [
    "# Control Reasoning with Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d0235f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, import all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bf56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_HOME = /data1/hf_cache/huggingface\n",
      "TRANSFORMERS_CACHE = /data1/hf_cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/data1/hf_cache/huggingface\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/data1/hf_cache/huggingface/hub\"\n",
    "\n",
    "print(\"HF_HOME =\", os.environ[\"HF_HOME\"])\n",
    "print(\"TRANSFORMERS_CACHE =\", os.environ[\"TRANSFORMERS_CACHE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97a4104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/py312/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "from transcoder_circuits.circuit_analysis import *\n",
    "from transcoder_circuits.feature_dashboards import *\n",
    "from transcoder_circuits.replacement_ctx import *\n",
    "\n",
    "from sae_training.sparse_autoencoder import SparseAutoencoder\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sae_training.config import LanguageModelSAERunnerConfig\n",
    "torch.serialization.add_safe_globals([LanguageModelSAERunnerConfig])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272433e5",
   "metadata": {},
   "source": [
    "Now, load the pre-trained model and transcoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccc8e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35cf981b1254abdaed7cc5c31ad826e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.1-8B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "device = \"cuda:0\"\n",
    "model = HookedTransformer.from_pretrained(model_name=model_name, device=device, n_devices=8, move_to_device=True)\n",
    "\n",
    "layer_idx = 0 # Change this to load different layers (0 9 18 27)\n",
    "transcoder_template = \"/data1/cl/weights/transcoder/transcoders/llama3.1_8b_instruct/layer_{:02d}/Llama-3.1-8B-Instruct_blocks.{}.ln2.hook_normalized_65536\"\n",
    "path = transcoder_template.format(layer_idx, layer_idx)\n",
    "\n",
    "transcoder = SparseAutoencoder.load_from_pretrained(f\"{path}.pt\").eval()\n",
    "frequency = torch.load(f\"{path}_log_feature_sparsity.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fe9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up memory\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98d1c6",
   "metadata": {},
   "source": [
    "Now, prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3ab8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"google/boolq\", split=\"validation\", streaming=True)\n",
    "raw_dataset = raw_dataset.shuffle(seed=42, buffer_size=10_000)\n",
    "raw_dataset = raw_dataset.take(300) # take 300 samples for val\n",
    "\n",
    "def make_prompt(ex):\n",
    "    q = ex[\"question\"].strip()\n",
    "    p = ex[\"passage\"].strip()\n",
    "    return f\"Question: {q}\\nPassage: {p}\\nAnswer:\"\n",
    "\n",
    "dataset = raw_dataset.map(lambda x: {\n",
    "    \"text\": make_prompt(x), \n",
    "    \"answer\": str(x[\"answer\"])\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af22ee",
   "metadata": {},
   "source": [
    "Also, get the index of reasoning neurons and memory neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64986d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_traces(out_dir, tracing_type):\n",
    "    combined_records = {}\n",
    "    \n",
    "    file_pattern = f\"{tracing_type}/*_{tracing_type}_feature_traces.pt\"\n",
    "    search_path = os.path.join(out_dir, file_pattern)\n",
    "    \n",
    "    batch_files = glob.glob(search_path)\n",
    "    \n",
    "    if not batch_files:\n",
    "        print(f\"No files found at: {search_path}\")\n",
    "        return {}\n",
    "\n",
    "    for f_path in batch_files:\n",
    "        batch_records = torch.load(f_path)\n",
    "        combined_records.update(batch_records)\n",
    "\n",
    "    return combined_records # [N, [T, D]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9011f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading basic: 100%|██████████| 512/512 [00:00<00:00, 4636.63it/s]\n",
      "Loading 0shot: 100%|██████████| 512/512 [00:00<00:00, 6183.23it/s]\n",
      "Loading fewshot: 100%|██████████| 512/512 [00:00<00:00, 4717.71it/s]\n"
     ]
    }
   ],
   "source": [
    "tracing_types = [\"basic\", \"0shot\", \"fewshot\"]\n",
    "titles = [\"Mean activation\", \"First step\", \"Last step\"]\n",
    "\n",
    "acts_dict = {}\n",
    "for tracing_type in tracing_types:\n",
    "    data = load_all_traces(out_dir=f\"/data1/cl/weights/transcoder/frequencies/llama3.1_8b_instruct/{layer_idx}_layer\", tracing_type=tracing_type)\n",
    "    all_acts = []\n",
    "    step_first = []\n",
    "    step_last = []\n",
    "\n",
    "    for text, trace_dict in tqdm.tqdm(data.items(), desc=f\"Loading {tracing_type}\"):\n",
    "        for step, vec in trace_dict.items():\n",
    "            all_acts.append(vec.unsqueeze(0))\n",
    "        if 0 in trace_dict and len(trace_dict) > 0:\n",
    "            step_first.append(trace_dict[0].unsqueeze(0))\n",
    "            step_last.append(trace_dict[max(trace_dict.keys())].unsqueeze(0))\n",
    "\n",
    "    all_acts = torch.cat(all_acts, dim=0)\n",
    "    step_first = torch.cat(step_first, dim=0)\n",
    "    step_last = torch.cat(step_last, dim=0)\n",
    "\n",
    "    mean_act = all_acts.mean(dim=0)\n",
    "    mean_first = step_first.mean(dim=0)\n",
    "    mean_last = step_last.mean(dim=0)\n",
    "\n",
    "    acts_dict[tracing_type] = {\n",
    "        \"mean\": mean_act,\n",
    "        \"first\": mean_first,\n",
    "        \"last\": mean_last\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502b113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_active = -6\n",
    "mask_alive = frequency > threshold_active\n",
    "\n",
    "a_basic = acts_dict[\"basic\"][\"mean\"]\n",
    "a_0shot = acts_dict[\"0shot\"][\"mean\"]\n",
    "a_fewshot = acts_dict[\"fewshot\"][\"mean\"]\n",
    "\n",
    "diff_0 = a_0shot - a_basic\n",
    "diff_f = a_fewshot - a_basic\n",
    "\n",
    "threshold = 1e-3 \n",
    "\n",
    "mask_reasoning = ((diff_0 > threshold) | (diff_f > threshold)) & mask_alive\n",
    "mask_memory = mask_alive & (~mask_reasoning)\n",
    "\n",
    "reasoning_neurons = torch.where(mask_reasoning)[0]\n",
    "memory_neurons = torch.where(mask_memory)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8e07c",
   "metadata": {},
   "source": [
    "## Control Reasoning Activation Strength\n",
    "\n",
    "First, val the model (with transcoder)'s performance without controlling any activation stength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38a4881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_steering_hook(transcoder, feature_indices, strength=1.0):\n",
    "    def hook_fn(activations, hook):\n",
    "        x = activations\n",
    "        acts = (x @ transcoder.W_enc.to(x.device)) + transcoder.b_enc.to(x.device)\n",
    "        feats = torch.relu(acts)\n",
    "        \n",
    "        if strength != 1.0:\n",
    "            feats[:, :, feature_indices] *= strength\n",
    "            \n",
    "        reconstruction = (feats @ transcoder.W_dec.to(x.device)) + transcoder.b_dec.to(x.device)\n",
    "        \n",
    "        return reconstruction\n",
    "\n",
    "    return hook_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baebbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_results(model, transcoder, dataset, reasoning_neurons, save_path=\"experiment_results.json\"):\n",
    "    results = []\n",
    "    \n",
    "    configs = [\n",
    "        (\"Base\", None),\n",
    "        (\"Original\", 1.0),\n",
    "        (\"Suppressed\", 0.5),\n",
    "        (\"Strengthen\", 2.0) \n",
    "    ]\n",
    "    \n",
    "    hook_point = transcoder.cfg.hook_point\n",
    "\n",
    "    for i, item in enumerate(tqdm.notebook.tqdm(dataset)):\n",
    "        prompt = item['text']\n",
    "        answer = item['answer']\n",
    "        input_tokens = model.to_tokens(prompt).to(device)\n",
    "        \n",
    "        record = {\n",
    "            \"id\": i,\n",
    "            \"prompt\": prompt,\n",
    "            \"ground_truth\": answer, \n",
    "            \"generations\": {}\n",
    "        }\n",
    "        \n",
    "        for name, strength in configs:\n",
    "            model.reset_hooks() \n",
    "            \n",
    "            gen_args = {\n",
    "                \"input\": input_tokens,\n",
    "                \"max_new_tokens\": 50, \n",
    "                \"temperature\": 0.0,\n",
    "                \"verbose\": False,\n",
    "                \"stop_at_eos\": True\n",
    "            }\n",
    "                \n",
    "            if strength is None:\n",
    "                output_ids = model.generate(**gen_args)\n",
    "            else:\n",
    "                my_hook = get_steering_hook(transcoder, reasoning_neurons, strength=strength)\n",
    "                \n",
    "                with model.hooks(fwd_hooks=[(hook_point, my_hook)]):\n",
    "                    output_ids = model.generate(**gen_args)\n",
    "            \n",
    "            full_text = model.to_string(output_ids[0])\n",
    "            generated_text = full_text[len(prompt):]\n",
    "            \n",
    "            record[\"generations\"][name] = generated_text\n",
    "                \n",
    "        results.append(record)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = f\"boolq_reasoning_control_layer{layer_idx}.json\"\n",
    "\n",
    "experiment_data = generate_and_save_results(\n",
    "    model=model, \n",
    "    transcoder=transcoder, \n",
    "    dataset=dataset, \n",
    "    reasoning_neurons=reasoning_neurons,\n",
    "    save_path=save_file\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
